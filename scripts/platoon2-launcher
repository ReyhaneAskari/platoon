#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
platoon2-launcher

This file serves as an executable for launching a training procedure with
Platoon. Depending on the given arguments or configuration, the training will
start in a single machine or multiple hosts. Execute `platoon2-launcher -h` to
see instructions or read the docs.

Exit Codes
----------
0: Success
1: A worker or controller has exited with non-success status
2: False arguments
3: Subprocess or OS errors
4: Other error

"""

from __future__ import print_function
import os
import sys
import subprocess
import signal
import time
import shlex
import argparse
import textwrap

from platoon.util import launch_process
from platoon import configparser


# TODO revise help
def parse_arguments():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent('''\
            ####################################################################
            #      Launcher for Platoon multi-node/GPU training framework      #
            ####################################################################
            Platoon will train your Theano models using many GPUs even if they
            do not reside on the same host.

            In order to work you have to provide a worker file, which defines
            the training process of a single set of model parameters in a
            parallel/distributed manner. Optionally and in case you want to
            extend the distributed computation capabilities of your training
            process, you can provide also a controller file that extends the
            default one in the framework.

            Platoon is configured through command line arguments and in case of
            their absence (or if needed) through environmental variables or
            platoonrc files. Please read `platoonrc.conf` in package's root
            directory on how to configure Platoon in total. If no control
            arguments out of the following are provided, then platoonrc is
            searched in current folder and then in user's home folder. If even
            then a platoonrc file cannot be found, then single-node usage is
            assumed with all GPU devices found on host participating in the
            computation.

            If single-node is explicitly specified, the specified devices will
            be used in the order they are parsed. The same thing applies for
            lists of devices found in platoonrc files.

            e.g. usage: platoon2-launcher lstm -D cuda0 cuda3
                        platoon2-launcher lstm

            If multi-node is explicitly specified, appropriate platoonrc files
            need to reside on the home folders of the specified hosts that
            describe which devices will participate in each host. Host names are
            given the same way they are given in MPI's `mpiexec`.

            e.g. usage: platoon2-launcher lstm -nw 2 2 -H pc01 pc02

            NOTIFICATION: For this launcher, currently only CUDA devices are
            supported. For multi-gpu NVIDIA's NCCL collectives library and pygpu
            are required, while for multi-node mpi4py is required in addition.
            '''))
    parser.add_argument('experiment_name', help='The name of your experiment. The launcher will expect to find the files <experiment_name>_worker.py and optionally <experiment_name>_controller.py.')
    parser.add_argument('-nw', '--workers', nargs='+', type=int, metavar='workers/host',
                        required=False, help='List the number of workers per controller in each host.')
    single_or_multi = parser.add_mutually_exclusive_group(required=False)
    single_or_multi.add_argument('-D', '--devices', nargs='+', type=str, metavar='devname',
                                 required=False, help='List of Theano device names (e.g. gpu0 or cuda1). Each device will be assigned to a separate worker. If this option is specified, experiment will be run in a single node.')
    single_or_multi.add_argument('-H', '--hosts', nargs='+', type=str, metavar='hostname',
                                 required=False, help='List of host names to participate in multi-node training. Each host will be assigned to a separate controller. If this option is specified, experiment will be run in multiple nodes.')

    return parser.parse_args()

if __name__ == '__main__':
    args = parse_arguments()

    logs_folder = os.path.join("PLATOON_LOGS", args.experiment_name, time.strftime("%Y-%m-%d_%H-%M"))
    os.makedirs(logs_folder)

    print("### Launching experiment: {}".format(args.experiment_name))

    # check for worker executable, else fail
    if not os.path.isfile("./{}_worker.py".format(args.experiment_name)):
        print("\nERROR! Cannot find worker executable: {}_worker.py".format(args.experiment_name))
        sys.exit(2)
    # TODO check for custom controller executable, else use default
    # so far this launcher supports only default controller type: platoon
    controller_type = "platoon"

    # If not specified in launcher, check for other configuration types
    if args.hosts is None:
        try:
            hosts = configparser.fetch_hosts()
        except KeyError:
            hosts = None
    else:
        hosts = args.hosts

    # Check if we run on multi-node
    if hosts is not None and len(hosts) > 1:
        # On multi-node, user must specify number of workers per controller
        if args.workers is None:
            print("\nERROR! Number of workers per host's controller must be given. Use '-nw' option.")
            sys.exit(2)

        if len(args.workers) > len(hosts):
            num_of_controllers = len(hosts)
            print("\nWARNING! Given more workers per host than number of hosts.")
        elif len(args.workers) < len(hosts):
            num_of_controllers = len(args.workers)
            print("\nWARNING! Given more hosts than number of 'workers per hosts'.")
        else:
            num_of_controllers = len(hosts)

        num_of_workers = args.workers[:num_of_controllers]

        print("### Starting multi-node/gpu training on: {} ...".format(args.hosts), end=' ')
        log_file = os.path.join(logs_folder, "multi-node-controllers.{}")
        with open(log_file.format("out"), 'w') as stdout_file:
            with open(log_file.format("err"), 'w') as stderr_file:
                env = dict(os.environ)
                theano_flags = "THEANO_FLAGS={0},device={1}".format(env.pop('THEANO_FLAGS', ''), "cpu")
                command = ["mpiexec", "-H"]
                command += [','.join(args.hosts[:num_of_controllers])]
                command += ["-n", str(num_of_controllers), "--map-by", "ppr:1:node"]
                command += shlex.split("-x " + " -x ".join(env.keys()) + " -x " + theano_flags)
                if controller_type == "platoon":
                    executable = ["-m", "platoon.controller"]
                else:
                    executable = ["{}_controller.py".format(controller_type)]
                for i, w in enumerate(num_of_workers):
                    command += ["python", "-u"] + executable
                    command += [args.experiment_name, "--multi", "-nw", str(w)]
                    # TODO Support controller args
                    #  if args is not None:
                    #      command += args
                    if i != len(num_of_workers) - 1:
                        command += ":"
                try:
                    p = subprocess.Popen(command, bufsize=0, stdout=stdout_file, stderr=stderr_file)
                except OSError as exc:
                    print("\nERROR! OS error in Popen: {}".format(exc))
                    sys.exit(3)
                except Exception as exc:
                    print("\nERROR! Other in Popen: {}".format(exc))
                    sys.exit(4)
        print("Done")
        experiment_type = "Multi-node Controllers"
    else:
        if hosts is not None:
            import socket
            hostname = socket.gethostname()
            if hosts[0] != hostname:
                print("\nERROR! A single host '{0}' was specified which is not "
                      "the same as the current host '{1}'.\nThis is not currently "
                      "supported.".format(hosts[0], hostname))
                sys.exit(2)
        num_of_controllers = 1
        controller_args = [args.experiment_name, '--single']
        if args.devices is not None:
            if args.workers is not None:
                if args.workers[0] > len(args.devices):
                    print("\nWARNING! Specified more workers per host than devices. Using number of devices.")
                    num_of_workers = len(args.devices)
                else:
                    num_of_workers = args.workers[0]
            else:
                num_of_workers = len(args.devices)
            controller_args += ['-D']
            controller_args += args.devices[:num_of_workers]
        else:
            if args.workers is None:
                print("\nERROR! Number of workers per host's controller must be given. Use '-nw' option.")
            num_of_workers = args.workers[0]
        controller_args += ["-nw", str(num_of_workers)]
        # TODO Support controller args
        #  if args is not None:
        #      command += args

        print("### Starting single-node multi-gpu training")
        try:
            p = launch_process(logs_folder, controller_type, controller_args, "cpu", "controller")
        except OSError as exc:
            print("\nERROR! OS error in Popen: {}".format(exc))
            sys.exit(3)
        except Exception as exc:
            print("\nERROR! Other while launching process: {}".format(exc))
            sys.exit(4)
        experiment_type = "Single-node Controller"

    print("\n### Logs folder ###\n{}".format(logs_folder))
    print("\n### Waiting on experiment to finish ...")
    try:
        pid, status = os.waitpid(p.pid, 0)
    except OSError as exc:
        print("\nERROR! OS error: {}".format(exc))
        sys.exit(3)
    if pid != p.pid:
        print("\nWARNING! Received status for unknown process {}".format(pid))
        sys.exit(3)
    if os.WIFEXITED(status):
        rcode = os.WEXITSTATUS(status)
        print("## {0} terminated with return code: {1}.".format(experiment_type, rcode))
        if rcode != 0:
            print("\nERROR! An error has occured.\nSee logs for more info.")
            sys.exit(1)
        else:
            print("\nSUCCESS! Training with platoon has finished.")
    else:
        print("\nWARNING! {} changed status but has not exited.".format(experiment_type))
        try:
            os.kill(pid, signal.SIGTERM)
            pid, status = os.waitpid(pid, 0)
        except OSError as exc:
            print("\nERROR! OS error: {}".format(exc))
        sys.exit(3)
